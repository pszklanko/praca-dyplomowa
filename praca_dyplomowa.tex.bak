\documentclass[a4paper,12pt,twoside,openany]{report}
%
% Wzorzec pracy dyplomowej
% J. Starzynski (jstar@iem.pw.edu.pl) na podstawie pracy dyplomowej
% mgr. inż. Błażeja Wincenciaka
% Wersja 0.1 - 8 października 2016
%
\usepackage{polski}
\usepackage{helvet}
\usepackage[T1]{fontenc}
\usepackage{anyfontsize}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{tabularx}
\usepackage{array}
\usepackage{listings}
\usepackage[polish]{babel}
\usepackage{subfigure}
\usepackage{amsfonts}
\usepackage{verbatim}
\usepackage{indentfirst}
\usepackage[pdftex]{hyperref}

\lstset{
	numbers=left
}


% rozmaite polecenia pomocnicze
% gdzie rysunki?
\newcommand{\ImgPath}{.}

% oznaczenie rzeczy do zrobienia/poprawienia
\newcommand{\TODO}{\textbf{TODO}}


% wyroznienie slow kluczowych
\newcommand{\tech}{\texttt}

% na oprawe (1.0cm - 0.7cm)*2 = 0.6cm
% na oprawe (1.1cm - 0.7cm)*2 = 0.8cm
%  oddsidemargin lewy margines na nieparzystych stronach
% evensidemargin lewy margines na parzystych stronach
\def\oprawa{1.05cm}
\addtolength{\oddsidemargin}{\oprawa}
\addtolength{\evensidemargin}{-\oprawa}

% table span multirows
\usepackage{multirow}
\usepackage{enumitem}	% enumitem.pdf
\setlist{listparindent=\parindent, parsep=\parskip} % potrzebuje enumitem

%%%%%%%%%%%%%%% Dodatkowe Pakiety %%%%%%%%%%%%%%%%%
\usepackage{prmag2017}   % definiuje komendy opieku,nrindeksu, rodzaj pracy, ...


%%%%%%%%%%%%%%% Strona Tytułowa %%%%%%%%%%%%%%%%%
% To trzeba wypelnic swoimi danymi
\title{Wykorzystanie protokołu HTTP/2 do budowy szybkiej aplikacji internetowej}

% autor
\author{Piotr Szklanko}
\nrindeksu{244145}

\opiekun{mgr inż. Bartosz Chaber}
\terminwykonania{1 lutego 2017} % data na oświadczeniu o samodzielności
\rok{2017}


% Podziekowanie - opcjonalne
% \podziekowania{\input{podziekowania.tex}}

% To sa domyslne wartosci
% - mozna je zmienic, jesli praca jest pisana gdzie indziej niz w ZETiIS
% - mozna je wyrzucic jesli praca jest pisana w ZETiIS
%\miasto{Warszawa}
%\uczelnia{POLITECHNIKA WARSZAWSKA}
%\wydzial{WYDZIAŁ ELEKTRYCZNY}
%\instytut{INSTYTUT ELEKTROTECHNIKI TEORETYCZNEJ\linebreak[1] I~SYSTEMÓW INFORMACYJNO-POMIAROWYCH}
% \zaklad{ZAKŁAD ELEKTROTECHNIKI TEORETYCZNEJ\linebreak[1] I~INFORMATYKI STOSOWANEJ}
\rodzajpracy{INŻYNIERSKA}
%\kierunekstudiow{INFORMATYKA}
%%% koniec od P.W

\opinie{%
  \input{opiniaopiekuna.tex}
  \newpage
  \input{recenzja.tex}
}

\streszczenia{
  \input{streszczenia.tex}
}

\begin{document}
\maketitle

%-----------------
% Wstęp
%-----------------
\chapter{Wstęp}
Moim celem jest przeprowadzenie testów protokołu HTTP w najnowszej wersji -- HTTP/2.
Obecnie powszechnie stosowana jest wersja 1.1, która została wprowadzona w roku 1999.
Jednakże szybki rozwój technologii internetowych sprawia, że wprowadzony osiemnaście lat temu protokół przestaje powoli spełniać swoje zadanie.
Obecnie bez wykorzystania takich środków jak:
\begin{enumerate}
	\item pamięć cache przeglądarki, dzięki której nie musimy przesyłać wszystkich plików naszej aplikacji do użytkownika, który korzysta z niej kolejny raz. 
	Wysyłamy jedynie to, co się zmieniło,
	\item wielu połączeń TCP -- wiele połączeń TCP oznacza straty związane z czasem wymaganym do nawiązania połączenia.
	Jest to szczególnie widoczne przy pobieraniu małych zasobów, gdzie czas nawiązania połączenia jest duży w stosunku do czasu wykonania samego zapytania.
	Niestety w przypadku HTTP/1.1 jest to jedyny sposób na jednoczesne przesyłanie wielu zasobów,
	\item łączenia plików -- sposób na ograniczenie liczby połączeń.
	Dzięki wykorzystaniu narzędzi takich jak webpack możemy ograniczyć liczbę połączeń TCP poprzez łączenie wielu plików danego typu w jeden duży plik.
	Na przykład gdy mamy wiele plików z arkuszami stylów możemy je połączyć w jeden.
	Jest to tylko mała część możliwości tego pakietu, zainteresowanych odsyłam do strony internetowej\cite{webpack}.
\end{enumerate}
nie jest możliwe stworzenie rozbudowanej aplikacji, która działałaby w sposób satysfakcjonujący użytkownika.
Gdyby zmiany, które ma wprowadzić protokół HTTP/2 faktycznie pozwalały zapomnieć o wspomnianych środkach, to życie wielu developerów stałoby się dużo łatwiejsze.
Dzięki temu mogliby się oni ten czas poświęcić na rozwój aplikacji.

Za pomocą własnoręcznie stworzonej aplikacji chcę przekonać się, czy wprowadzone funkcje faktycznie mają tak ogromny wpływ na szybkość komunikacji pomiędzy klientem i serwerem.

Swoją aplikację stworzyłem wykorzystując zestaw oprogramowania MEAN -- MongoDB, Express.js, Angular i Node.js.

\begin{itemize}
	\item MongoDB -- baza danych NoSQL,
	\item Express.js -- framework Node.js do tworzenia aplikacji sieciowych od strony serwera.
	Udostępnia on wiele metod ułatwiających obsługę zapytań HTTP, routing zapytań, renderowanie widoków HTML,
	\item Angular -- framework JavaScript służący do budowy dynamicznych aplikacji internetowych od strony użytkownika,
	\item Node.js -- środowisko uruchomieniowe języka JavaScript, które pozwala wystartować serwer.
\end{itemize}

Zdecydowałem się na to rozwiązanie z kilku powodów:

\begin{itemize}
	\item po przejrzeniu dostępnych w sieci informacji doszedłem do wniosku, że implementacja protokołu HTTP/2 jest najlepiej opisana oraz wspierana przez środowisko związane z JavaScriptem,
	\item dobra znajomość języka JavaScript oraz jednoczesna chęć rozwoju umiejętności tworzenia aplikacji w tym języku,
	\item chęć poszerzenia wiedzy dotyczącej budowania aplikacji internetowych za pomocą technologii javascriptowych,
	\item nie ukrywam, że znaczący wpływ na moją decyzję miała również popularność języka JavaScript na rynku pracy.
\end{itemize}

Dodatkowo, poza narzędziami składającymi się na zestaw MEAN, wykorzystałem następujące biblioteki:
\begin{enumerate}
	\item node-spdy -- zewnętrzny moduł do node.js, który umożliwia tworzenie serwerów wspierających HTTP/2.
	Jest on kompatybilny z biblioteką Express.js, którą wykorzystuję w swoim projekcie.
	Dzięki temu modułowi możemy zaimplementować serwer HTTP/2 wraz z Server Push.
	Pomimo, że nie jest to oficjalny moduł node.js, to trwające obecnie prace, które mają na celu wdrożenie HTTP/2 oficjalnie do node.js bazują na tej bibliotece,
	\item mongoose -- ułatwia modelowanie danych mongoDB, walidację oraz pisanie logiki biznesowej. 
\end{enumerate}

%-----------------
% HTTP/2.0
%-----------------
\chapter{HTTP/2}

\section{Historia}
\label{sectionHistoria}
Pracę nad zmianami w protokole zapoczątkowała w 2009 roku firma Google ze swoim projektem SPDY.
Zdecydowali się oni na stworzenie protokołu, który miał usprawnić działanie aplikacji oraz stron internetowych rozwiązując ograniczenia nałożone przez HTTP/1.1.
Z biegiem czasu coraz więcej przeglądarek oraz stron internetowych, zarówno tych dużych jak i tych małych, zaczęło wspierać SPDY, co zainteresowało osoby pracujące nad protokołem HTTP.
Zdecydowali się oni wykorzystać dokumentację protokołu SPDY jako początek prac nad własnym protokołem -- HTTP/2.
Od tego momentu aż do roku 2015, kiedy to standard HTTP/2 został oficjalnie zaakceptowany 
(\TODO odnośnik RFC 7540 i może 7541), projekty były rozwijane równolegle.
SPDY było wykorzystywane do testów nowych funkcjonalności, które miały zostać wprowadzone do nowego protokołu HTTP.
Niedługo po oficjalnym zaakceptowaniu HTTP/2 ogłoszono, że SPDY nie będzie dalej wspierane.

W kilku poniższych akapitach postaram się przybliżyć zmiany, które zostały wprowadzone do protokołu HTTP.

\section{Protokół binarny}
\label{sectionProtokolBinarny}

Kluczową zmianą, która determinuje brak wstecznej kompatybilności z HTTP/1.1, jest przejście na kodowanie binarne przesyłanych wiadomości. Przykładowa ramka widoczna jest na rysunku \ref{schematRamki}
\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=1.0]{\ImgPath/rys/ramka.png}
\end{center}
	\caption{Schemat ramki protokołu HTTP/2}
	\label{schematRamki}
\end{figure}
Jest to rozwiązanie dużo bardziej kompaktowe i łatwiejsze w implementacji, niż przesyłanie zwykłego tekstu.
Dzięki temu zabiegowi w ramach jednego połączenia TCP z serwerem może zostać utworzonych wiele dwukierunkowych strumieni danych przesyłających wiadomości HTTP.
Taka wiadomość to w rzeczywistości zapytanie od klienta lub odpowiedź serwera składające się z ramek.
Każda ramka natomiast musi przynajmniej posiadać nagłówek z informacją, do którego strumienia danych należy.
Kodowanie binarne nie ma wpływu na składnie zawartości ramki -- wszystkie nagłówki czy zapytania HTTP/1.1 pozostawiono bez zmian.

\section{Multiplexing}
\label{sectionMultiplexing}
W poprzedniej wersji protokołu, pomimo, że istniała możliwość przesyłania wielu zapytań w ramach jednego połączenia, nie można było wykonywać ich równolegle.
Każde zapytanie musiało być rozpatrywane i odesłane przez serwer do klienta zgodnie z kolejnością nadania, co powodowało efekt HOL (head-of-line blocking ODNOSNIK  DO JAKIEGOŚ ŹRÓDŁA?).
Aby wykonywać zapytania równolegle należało utworzyć kilka zapytań TCP, co obciąża serwer oraz jest czasochłonne.
Protokół HTTP/2 umożliwia przesyłanie oraz odbieranie wielu wiadomości jednocześnie, co pokazuje schemat na rysunku \ref{schematMultiplexing}.
\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/multiplexing.png}
\end{center}
	\caption{Schemat wykorzystania multiplexingu w HTTP/2}
	\label{schematMultiplexing}
\end{figure}
Są one rozbijane na pojedyncze ramki, przesyłane, a następnie odczytywane i składane z powrotem w całość po stronie odbiorcy.
Dzięki temu nie jest już konieczne uciekanie się do takich zabiegów jak:
\begin{itemize}
	\item scalanie plików (WEBPACK),
	\item  wykorzystywanie spritów,
	\item domain sharding (DOCZYTAC).
\end{itemize}
To wszystko sprawia, że aplikacje stają się szybsze oraz prostsze.

\section{Pierwszeństwo}

% wspomne o tym jesli zrobie testy

\section{Server push}
\label{sectionServerPush}

Wykorzystując protokół HTTP/1.1 nie mamy możliwości otrzymania zasobu, o który nie poprosiliśmy wysyłając zapytanie.
Powoduje to opóźnienia na przykład podczas ładowania strony internetowej.
Zanim otrzymamy skrypty czy arkusze styli, które wykorzystuje nasza strona musi ona o nie poprosić.
Zapytanie do serwera wysyłane jest gdy w kodzie pliku HTML napotkamy na taki kod (przykład z mojego projektu):
\begin{lstlisting}
<!-- CSS -->
<link rel="stylesheet"
	  href="libs/bootstrap/dist/css/bootstrap.min.css">
<link rel="stylesheet"
      href="libs/font-awesome/css/font-awesome.min.css">

<!-- JS -->
<script src="libs/angular/angular.min.js"></script>
\end{lstlisting}
Takie rozwiązanie, chociaż w wielu przypadkach jest pożądane, tutaj jedynie spowalnia działanie aplikacji.
Jeżeli mamy pewność, że użytkownik będzie potrzebował danych zasobów \ref{schematPush} możemy mu je od razu udostępnić, co zdecydowanie skraca czas ładowania aplikacji i dzięki temu unikam niechcianego efektu, gdy strona się załaduje, ale na przykład bez pliku zawierającego style, który jest dopiero przesyłany.
\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/push.png}
\end{center}
	\caption{Schemat Server push HTTP/2}
	\label{schematPush}
\end{figure}

%Podstawowy scenariusz, powszechny w literaturze na temat steganografii, odnosi 
%się do sytuacji opisanej w \cite{PrisonersProblem}. Dwóch więźniów (w naszym 
%przypadku Alicja(\tech{A}) i Bob(\tech{B})) zamknięci są w dwóch odrębnych 
%celach. 
%
%Przedstawioną tak sytuację pokazuje rysunek 
%\ref{schematKomunikacji}\footnote{sporządzony na podstawie 
%\cite{schematKomunikacjiPrzypis}, rysunek 1, strona 3}. \tech{A} próbuje 
%przesłać tajną informację \tech{E} do \tech{B}. Cała komunikacja odbywa się 
%przez kanał publiczny, kontrolowany przez \tech{W}. W celu ukrycia faktu 
%komunikacji \tech{A} stara się ukryć tajny przekaz w informacji \tech{C}. W celu 
%uzyskania skutecznej steganografii \tech{W} nie może rozróżnić informacji 
%poprawnej, nie zawierającej tajnych danych, od informacji \tech{S}, która 
%zawiera tajną informację. W celu dodatkowego zabezpieczenia przekazu, \tech{A} i 
%\tech{B} mogą korzystać z funkcji kryptograficznej zabezpieczającej przekazywane 
%informacje. Można tu wykorzystać metody kryptografii symetrycznej (ustalony 
%klucz kryptograficzny \tech{K}) lub niesymetrycznej (klucz publiczny 
%\tech{K}$_{pub}$ i klucz prywatny \tech{K}$_{pryw}$).


\section{Kompresja nagłówków}

Kolejną ważną, chociaż pozornie niezauważalną zmianą jest kompresja nagłówków.
Pomimo, że problem może wydawać się marginalny, to te kilka bajtów w każdym zapytaniu potrafi dość mocno wydłużyć czas komunikacji z serwerem.
HTTP/2 wykorzystuje format kompresji zwany HPACK, który dzięki wykorzystaniu dwóch technik -- kodowania oraz indeksowania, jest w stanie znacznie usprawnić komunikację ze względu na nagłówki.
Po pierwsze kodowanie Huffmana znacznie kompresuje przesyłane dane.
Dodatkowo klient oraz serwer przechowują listę widzianych wcześniej nagłówków i nie ma potrzeby wysyłania za każdym razem całego nagłówka.
Przesyłamy jedynie pola, które się zmieniły (patrz rysunek \ref{schematHeaderComp}).

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/headercomp.png}
\end{center}
	\caption{Kompresja nagłówków w HTTP/2}
	\label{schematHeaderComp}
\end{figure}

\chapter{Budowa aplikacji}

% \section{Struktura aplikacji}
\section{node-spdy -- konfiguracja serwera}

Najważniejszym elementem aplikacji jest konfiguracja serwera, który będzie w stanie obsłużyć zapytania HTTP/2.
Jak pokazuje poniższy listing na początku należy ustawić opcje naszego serwera:

\begin{enumerate}
	\item plain -- jeśli opcja jest włączona, to serwer wykorzystuje tekstową wersję protokołu HTTP, 
	\item ssl -- ustawienia zabezpieczeń połączenia,
	\item protocols -- lista protokołów, z których możemy korzystać,
	\item key -- klucz prywatny do połączeń SSL,
	\item cert -- certyfikat serwera do połączenia SSL.
\end{enumerate}

Następnie uruchamiamy nasz serwer HTTP za pomocą polecenia createServer i podajemy mu naszą konfigurację oraz informację o tym, jak ma się zachować, gdy otrzyma zapytanie od klienta.
W tym wypadku jest to moja aplikacja, więc za każdym razem, gdy serwer otrzyma zapytanie, będzie korzystał ze stworzonych przeze mnie funkcjonalności.

Na koniec musimy sprawić, aby nasz serwer nasłuchiwał przychodzących połączeń.
Osiągniemy to przy pomocy funkcji listen(), do której przekazujemy port, na którym nasza aplikacja ma działać.
Jeśli wszystko zakończy się pomyślnie otrzymamy informację o tym, że aplikacja działa na wybranym przez nas porcie.
Jeśli nie, to zostanie zwrócony komunikat o błędzie.

\begin{lstlisting}
var spdy           = require('spdy');
var port           = 8080;
var fs             = require('fs');
var app            = express();

	...
	...
	
const options = {
  spdy: {
    plain: true,
    ssl: false,
    protocols: ['h2', 'http/1.1'],
  },
  key: fs.readFileSync(__dirname + '/server.key'),
  cert: fs.readFileSync(__dirname + '/server.crt')
};

spdy
  .createServer(options, app)
  .listen(port, (error) => {
    if (error) {
      console.error(error);
      return process.exit(1);
    } else {
      console.log('Listening on port ' + port + '.');
    }
  });
\end{lstlisting}

Jak widać podstawowa konfiguracja serwera HTTP/2 z wykorzystaniem biblioteki node-spdy(ODNOSNIK) jest dość prostym zadaniem.
Należy jedynie pamiętać o wszystkich ustawieniach oraz wygenerowaniu kluczy dla połączenia SSL, bez których serwer niestety nie ruszy.

\section{Server Push}

Najbardziej wymagającą częścią projektu było zaimplementowanie funkcjonalności server push.
Ostatecznie udało się stworzyć podstronę, która do pełnego działania wymaga biblioteki jQuery.
Normalnie biblioteka ta byłaby wysłana dopiero po odczytaniu pliku push.html przez klienta i wysłaniu zapytania z prośbą o przesłanie jQuery.
Jest to rozwiązanie, w którym tracimy czas na wysłanie zapytania o zasób, który mógł być wysłany od razu.
Server Push zaimplementowany w HTTP/2 daje nam taką możliwość.

Patrząc na poniższy przykład postaram się przybliżyć sposób, w jaki udało mi się zaimplementować tę funkcjonalność.
Najpierw tworzymy routing dla ścieżki '/push'.
W nim, w zależności od tego co chcemy przesłać, scenariusz będzie trochę inny.
W moim przypadku przesyłam zawartość strony w postaci kodu HTML oraz bibliotekę jquery.
Najpierw wczytujemy plik i zapisujemy jego zawartość.
Jeśli wszystko zostało wykonane pomyślnie, to zapisujemy zawartość pliku HTML do wysłania jako odpowiedź na zapytanie użytkownika.
Następnie wczytujemy zawartość pliku z biblioteką jQuery i umieszczamy ją w strumieniu danych wysyłanym w ramach funkcji Push.
Ustawiamy nagłówki symulowanej prośby, typ odpowiedzi oraz dołączamy zawartość pliku, którą chcemy przesłać.
Zamykamy strumień danych i kończymy odpowiedź komendą res.end().
Oczywiście w ramach jednego zapytania możemy przesłać wiele zasobów.
Tworzymy po prostu kolejne strumienie danych analogicznie do pierwszego, który jest przedstawiony poniżej.

Server Push pomimo ogromnych usprawnień, których wyniki przybliżę w jednym z kolejnych rozdziałów, obarcza dewelopera pewną odpowiedzialnością.
W związku z tym, że klient nie prosił o dane zasoby musimy koniecznie wypełnić nagłówek przesyłanego zasobu, aby przeglądarka mogła odpowiednio zareagować na odebrany zasób.
Na przykład po prostu go odrzucić, gdy na przykład znajduje się on już w pamięci podręcznej.
Jest to rozwiązane za pomocą PUSH\textunderscore PROMISE, które jest wysyłane do klienta przed faktycznym przesłaniem całego strumienia.
Jeśli klient zechce, to może odrzucić dany strumień wysyłając ramkę RST\textunderscore STREAM.

\begin{lstlisting}
app.get('/push', function(req, res) {
  fs.readFile('/push.html', function read(err, data) {
    if(err) {
      throw err;
    }
    content = data;
    res.write(content)
  })

  fs.readFile('/jquery.js', function read(err, data) {
    if(err) {
      throw err;
    }
    content = data;
    var stream = res.push('/libs/jquery/dist/jquery.js', {
      status: 200, // optional
      method: 'GET', // optional
      request: { accept: '*/*' },
      response: { 'content-type': 'application/javascript' }
    })
    stream.on('error', function(err) {
      console.log(err);
    })
    stream.end(content)
    res.end();
  })
})
\end{lstlisting}

Ciekawy jest też wygląd okienka szczegółów zapytania w Google DevTools.
Na rysunku \ref{schematNoPushDetails} widzimy przykład zapytania bez wykorzystania server push.
Znajdują się tutaj typowe informacje dla zwykłego zapytania HTTP.
Dokładnie mam w tym wypadku na myśli czas wysłania zapytania oraz oczekiwania na początek odpowiedzi od serwera.
Natomiast na rysunku \ref{schematPushDetails} nie ma tych informacji.
Świadczy to o tym, że klient nie wysłał prośby o dany plik, a mimo to został on wysłany.
Dodatkowym potwierdzeniem, że korzystamy z server push jest informacja, że inicjatorem zapytania jest Push.
Widać też, że czas zapytania to prawie 3 razy mniej dla danych przesłanych z wykorzystaniem możliwości HTTP/2.
Widać tutaj jak dużo czasu trwa oczekiwanie na zasoby, które mogłyby zostać wysłane od razu.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/noPushDetails.png}
\end{center}
	\caption{Szczegóły zapytania wysłanego bez wykorzystania Server Push}
	\label{schematNoPushDetails}
\end{figure}

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/pushDetails.png}
\end{center}
	\caption{Szczegóły zapytania wysłanego z wykorzystaniem Server Push}
	\label{schematPushDetails}
\end{figure}

\chapter{Testy}

\section{Chrome DevTools}

Do pomiaru prędkości oraz uzyskania innych ważnych informacji wykorzystałem narzędzie Chrome DevTools.
Opiszę tutaj pokrótce co i jak mierzyłem za pomocą tego oprogramowania.

Po uruchomieniu konsoli przeglądarki przechodzimy do zakładki Network i naszym oczom ukazuje się okno jak na rysunku \ref{schematDevops}.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/devops.png}
\end{center}
	\caption{Wygląd okna Chrome DevTools}
	\label{schematDevops}
\end{figure}

Widoczne okno składa się z pięciu głównych elementów:
\begin{enumerate}
	\item paska kontroli -- umożliwia on między innymi edycję wyglądu panelu sieciowego,
	\item paska filtrów -- pozwala na stworzenie reguł i wybór tylko tych pakietów, które nas interesują,
	\item paska przeglądu -- ukazuje nam oś czasu, która daje nam obraz tego, jak przesyłane były pakiety danych,
	\item tabeli zapytań -- zawiera szczegółowe informacje na temat każdego zapytania
	\item podsumowania -- zawiera informacje o łącznej liczbie zapytań, przesłanych danych oraz czasie trwania.
\end{enumerate}

W moich badaniach najczęściej korzystałem z informacji zawartych w tabeli zapytań, a szczególnie z przedstawionej w niej osi czasu.
Po najechaniu kursorem na którykolwiek pasek na osi otrzymujemy szczegółowe informacje o czasie każdego z etapów zapytania jak na rysunku \ref{schematResourceTiming}.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/resource-timing-data.png}
\end{center}
	\caption{Szczegółowe informacje na temat czasu zapytania}
	\label{schematResourceTiming}
\end{figure}

\section{Przygotowanie testów}

Przed przejściem do porównania prędkości działania obu wersji protokołu chciałem zaprezentować pierwsze efekty implementacji protokołu HTTP/2, które przedstawia rysunek \ref{schematWorkingExample}.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/workingExample.png}
\end{center}
	\caption{Dowód działania protokołu HTTP/2}
	\label{schematWorkingExample}
\end{figure}

Widzimy tutaj dwie rzeczy, które powinny nas zainteresować. W sekcji 'Protocol' oznaczonej na rysunku \ref{schematWorkingExample} numerem 1 widnieje napis h2 przy każdym zapytaniu.
Jest to informacja, że do komunikacji z serwerem wykorzystana została najnowsza wersja protokołu HTTP.
Dodatkowo w sekcji 'Connection ID' (na rysunku \ref{schematWorkingExample} jest to numer 2) widzimy, że wszystkie zapytania zostały wykonane z wykorzystaniem tego samego połączenia TCP.
Nie mogłoby to mieć miejsca, gdybyśmy wykorzystali HTTP/1.1, co pokazuje rysunek \ref{schematWorkingExampleH1}.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/workingExampleH1.png}
\end{center}
	\caption{Przykładowe linia czasu dla zapytań wykonanych w HTTP/1.1}
	\label{schematWorkingExampleH1}
\end{figure}

Na rysunku widzimy, że protokół z jakiego korzystamy to HTTP/1.1, a wszystkie zapytania, które są wykonywane równolegle przesyłane są w ramach różnych połączeń TCP.
Świadczą o tym wartości w kolumnie 'Connection ID'.

Jeszcze jedną ciekawą rzeczą są wielkości nagłówków.
Dzięki przejściu na kodowanie binarne nagłówki w protokole HTTP/2 są o wiele mniejsze niż te w jego starszym bracie.
W swojej pracy stworzyłem możliwość wysłania zapytania, które w odpowiedzi dostaje odpowiedź w postaci samego nagłówka.
Dzięki temu można porównać wielkość nagłówków HTTP na konkretnym przykładzie,
Wyniki przedstawiają rysunki \ref{schematEmptyRes} i \ref{schematEmptyResH1}.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/emptyRes.png}
\end{center}
	\caption{Pusta odpowiedź w HTTP/2}
	\label{schematEmptyRes}
\end{figure}

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/emptyResH1.png}
\end{center}
	\caption{Pusta odpowiedź w HTTP/1.1}
	\label{schematEmptyResH1}
\end{figure}

Od razu widać, że nagłówki w najnowszej wersji protokołu uległy znacznej kompresji. 

%Przed przejściem do właściwych testów chciałem jeszcze zaznaczyć, że protokół HTTP/2 wymga wykorzystanie %bezpiecznego połączenia.
%Wygenerowałem własny certyfikat oraz potrzebne klucze i będę korzystał z bezpiecznego połączenia we wszystkich %pomiarach.

\section{Porównanie prędkości protokołu HTTP/2 i HTTP/1.1}

W ramach tego testu sprawdzałem prędkość ładowania wszystkich zasobów strony z wyłączonym CACHE przeglądarki oraz z ustawioną prędkością Regular 4G (20ms, 4.0 Mb/s, 3.0 Mb/s).
Dane z wykorzystaniem protokołu HTTP/1.1 są przesyłane za pomocą niezabezpieczonego połączenia.
HTTP/2 do utworzenia połączenia wymaga zabezpieczenia SSL.

\begin{tabular}{c|c|c}
Próba & HTTP/1.1 & HTTP/2 \\ \hline
1 & 1.23s & 1.26s\\
2 & 1.49s & 1.12s\\
3 & 1.28s & 1.39s\\
4 & 1.20s & 1.09s\\
5 & 1.22s & 1.09s\\
6 & 1.25s & 1.26s\\
7 & 1.21s & 1.12s\\
8 & 1.25s & 1.11s\\
9 & 1.21s & 1.16s\\
10 & 1.26s & 1.10s\\ \hline
ŚREDNIA & 1.26s & 1.17s\\
\end{tabular}

Tabela ukazuje wyniki wykonanych pomiarów.
Jak widać protokół HTTP/2 przyśpiesza czas ładowania strony o około 15\%.
W dużej mierze jest to czas zaoszczędzony na nawiązywanie nowych połączeń TCP.
Sporą oszczędność utrzymujemy też dzięki zmniejszeniu objętości nagłówków odpowiedzi.

Na rysunkach \ref{schematBasicTest} oraz \ref{schematBasicTestH1} widoczny jest przykładowy wynik testu.
W sekcji podsumowania widoczna jest całkowita objętość przesłanych danych. Są to odpowiednio 443 KB i 439 KB dla protokołu HTTP/1.1 i HTTP/2,
Możemy też porównać objętości oraz czasy przesyłania poszczególnych plików.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/basicTest.png}
\end{center}
	\caption{Test dla HTTP/2}
	\label{schematBasicTest}
\end{figure}

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/basicTestH1.png}
\end{center}
	\caption{Test dla HTTP/1.1}
	\label{schematBasicTestH1}
\end{figure}

\section{Porównanie prędkości przy bezpiecznym połączeniu HTTP/1.1}

W tym teście dane przesyłane za pomocą protokołu HTTP/1.1 są zabezpieczone SSL.

\begin{tabular}{c|c|c}
Próba & HTTP/1.1 & HTTP/2 \\ \hline
1 & 1.22s & 1.25s \\
2 & 1.49s & 1.29s \\
3 & 1.27s & 1.20s \\
4 & 1.26s & 1.18s \\
5 & 1.27s & 1.17s \\
6 & 1.26s & 1.24s \\
7 & 1.26s & 1.20s \\
8 & 1.26s & 1.23s \\
9 & 1.31s & 1.21s \\
10 & 1.36s & 1.17s\\ \hline
ŚREDNIA & 1.29s & 1.21s \\
\end{tabular}

Wyniki poniższego testu kolejny raz pokazują wyższość nowszej wersji protokołu HTTP.
Jednakże różnica 6\% nie pozwala powiedzieć, że jest to ogromna różnica.
Na podstawie tego testu widzimy też, że w przypadku wykorzystania zabezpieczonego połączenia czasy w przypadku HTTP/1.1 są minimalnie większe, niż bez wykorzystania tego protokołu.

\section{Porównanie prędkości dla HTTP/1.1 z włączonym CACHE}

\begin{tabular}{c|c|c}
Próba & HTTP/1.1 & HTTP/2 \\ \hline
1 & 709ms & 534ms \\
2 & 555ms & 483ms \\
3 & 622ms & 527ms \\
4 & 625ms & 511ms \\
5 & 550ms & 518ms \\
6 & 546ms & 555ms \\
7 & 603ms & 557ms \\
8 & 517ms & 496ms \\
9 & 584ms & 531ms \\
10 & 521ms & 532ms \\ \hline
ŚREDNIA & 583ms & 524ms \\
\end{tabular}

Kolejny test, w którym nieznacznie wygrywa nowsza wersja protokołu -- około 11\%.
Jak można było się spodziewać czasy z wykorzystaniem pamięci podręcznej przeglądarki będą znacznie mniejsze, niż gdy ta pamięć jest wyłączona.
Pokazuje to jak ważnym elementem pracy twórcy aplikacji internetowych jest rozsądne zarządzanie zasobami, które mogę być przechowywane w pamięci podręcznej po stronie klienta i nie muszą one być za każdym razem wysyłane ponownie.

Obrazują to poniższe rysunki. Na rysunku \ref{schematNoCacheExample} widzimy, co się dzieje, gdy pierwszy raz wchodzimy na daną stronę lub mamy wyłączoną pamięć podręczną przeglądarki.
Czas pobierania niektórych zasobów (niebieska część paska) jest elementem, który zabiera najwięcej czasu.
Natomiast, gdy spojrzymy na rysunek \ref{schematCacheExample}, to praktycznie nie widzimy niebieskiej części paska.
Taka sytuacja ma miejsce, gdy wchodzimy na stronę kolejny raz.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/cacheExample.png}
\end{center}
	\caption{Przykład zapytania z wykorzystaniem CACHE}
	\label{schematCacheExample}
\end{figure}

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/noCacheExample.png}
\end{center}
	\caption{Przykład zapytania bez wykorzystania CACHE}
	\label{schematNoCacheExample}
\end{figure}


\section{Porównanie prędkości przy wykorzystaniu Server Push}

Ostatni test chciałem przeprowadzić dla zapytania wykorzystującego wprowadzony przez HTTP/2 server push, który, z punktu widzenia programisty aplikacji internetowych, wydaje się być najciekawszą nowością wprowadzoną do protokołu HTTP.
Mądre wykorzystanie tej funkcji zdecydowanie ułatwi pracę każdemu programiście.

\begin{tabular}{c|c|c}
Próba & HTTP/1.1 & HTTP/2 \\ \hline
1 & 454ms & 387ms \\
2 & 441ms & 372ms \\
3 & 515ms & 351ms \\
4 & 436ms & 471ms \\
5 & 342ms & 415ms \\
6 & 438ms & 420ms \\
7 & 385ms & 470ms \\
8 & 450ms & 253ms \\
9 & 481ms & 269ms \\
10 & 413ms & 409ms \\ \hline
ŚREDNIA & 436ms & 382ms \\
\end{tabular}

Wyniki przeprowadzonego testu pokazują, że server push jest nowością z największym potencjałem na przyszłość.
Polepszenie wyników o około 14\% to dobra wróżba na przyszłość.
Kiedy technologia się rozwinie i zacznie powstawać wiele aplikacji wykorzystujących server push zaczną powstawać nowe, coraz lepsze sposoby jego wykorzystania.

Poniższe obrazki (\ref{schematNoPushExample} i \ref{schematPushExample}) ukazują przykładowe porównanie dwóch zapytań z powyższego testu.

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/noPushExample.png}
\end{center}
	\caption{Przykład zapytania bez wykorzystania Server Push}
	\label{schematNoPushExample}
\end{figure}

\begin{figure}[!htbp]
	\begin{center}
\centering
\includegraphics[scale=0.6]{\ImgPath/rys/pushExample.png}
\end{center}
	\caption{Przykład zapytania wykorzystującego Server Push}
	\label{schematPushExample}
\end{figure}

\chapter{Wnioski}

% co jeszcze moglem zrobic
% testy pusha z webpackiem
% testy z poziomu TCP
% testy na wiekszych rzeczach

Gdy tylko zobaczyłem informacje dotyczące najnowszej protokołu HTTP w wersji 2 bardzo się ucieszyłem.
Po pierwsze w obecnych czasach, gdy technologia tak szybko porusza się do przodu, korzystanie z rozwiązań, które nie zmieniły się od ponad 15 latu wydaje się nieco śmieszne.
HTTP/1.1 coraz mocniej ogranicza możliwości programistów i nie pozwala rozsądnie i w pełni wykorzystać możliwości, którymi dzisiaj dysponujemy.
Po przeczytaniu informacji, że numer dwa przy wersji protokołu, to właściwie tylko informacja o tym, że nie jest on wstecznie kompatybilny zacząłem się zastanawiać czy nie jest to swego rodzaju uspokojenie pokładanych w tym protokole oczekiwań.
Postanowiłem więc przeprowadzić testy, których wynikiem jest niniejsza praca.

Tak jak wspominałem moje oczekiwania co do wydajności protokołu były bardzo duże i dlatego po zobaczeniu wyników nieco się zawiodłem.
Owszem, widać przyśpieszenie, ale nie jest one godne otrzymania numeru 2, który jednak na początku sugerował ogromną rewolucję.
Wyniki badań szybkości, chociaż wypadały z korzyścią dla HTTP/2, nie są tak dobre, jak się spodziewałem.

Z drugiej strony protokół HTTP/2 to nie tylko szybkość, ale też jakość połączenia i jego bezpieczeństwo.
Bardzo dobrym krokiem jest wymuszanie na twórcach korzystanie z certyfikatów bezpieczeństwa.
Na pewno sprawi to, że sieć będzie się stawać coraz bezpieczniejszym miejscem i o wiele trudniej będzie przestępcy wykorzystać zwykłego użytkownika.

Wykorzystanie multiplexingu rozwiązało ostatecznie problem HOL blocking (ODNOSNIK), który w niektórych przypadkach potrafił bardzo mocno spowolnić działanie aplikacji. 
Oczywiście były sposoby, żeby sobie z tym poradzić.
Przykładem jest wykorzystywanie wielu połączeń TCP do przesyłania informacji równolegle.
Takie rozwiązanie jednak znacznie bardziej obciąża serwer niepotrzebnymi prośbami o połączenie.
Multiplexing pozwala na przesyłanie wielu informacji w ramach jednego połączenia, a dodatkowo kolejność przesyłanych informacji nie ma znaczenia.

Kolejny element, czyli kompresja nagłówków.
Może nie jest on tak znaczący dla zasobów o bardzo dużej objętości.
Możemy dojść do takiego wniosku na pierwszy rzut oka, jednak podsumowując powtarzającą się część nagłówków, widać, że ma to niemałe przełożenie na ilość przesyłanych danych.

Jak widać chociaż na razie HTTP/2 lekko zawiódł moje oczekiwania, to na pewno nie oznacza, że jego wprowadzenie było niepotrzebne. Jestem świadomy, że przed wyciągnięciem takiego wniosku należałoby wykonać dużo bardziej dogłębne testy. Jest to mój cel na przyszłość.

Chciałbym przede wszystkim dużo dokładniej przetestować możliwości Server Push oraz kompresji nagłówków. Można to osiągnąć poprzez znaczne rozbudowanie aplikacji tak, aby przypominała ona dużo bardziej dzisiejsze aplikacje, które są bardzo rozbudowane pod względem zasobów.

Ciekawym badaniem mogłoby być również prześledzenie czasu, który jest wykorzystywany tylko i wyłącznie na nawiązanie połączenia TCP.
Jak wspominałem protokół HTTP/1.1 nawiązuje kilka połączeń w ramach komunikacji klienta z serwerem.
Chciałbym się przekonać, czy faktycznie zmiany wprowadzone przez HTTP/2 są na tym poziomie bardzo widoczne.

Podsumowując, przeprowadzone testy wskazują, że HTTP/2 ma bardzo duży potencjał na przyszłość.
Na razie wyniki badań nie są powalające, ale może to również wynikać z jakości dostępnych narzędzi.
Wraz z czasem poznamy lepiej nową technologię i będą się pojawiać biblioteki, które dużo lepiej zaczną wykorzystywać jej możliwości. Na razie ciekawym rozwiązaniem może być śledzenie prac, które są wykonywane, aby oficjalnie wdrożyć ten protokół w node.js (ODNOŚNIK).

%-----------------
% Dodatki 
%-----------------
%\appendix
%\chapter{}


\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}
\bibitem{RFC7540}{M. Belshe, BitGo, R. Peon, Google, Inc, M. Thomson, Ed. Mozilla, ,,Hypertext Transfer Protocol Version 2 (HTTP/2)``, 2015.\newline \url{https://tools.ietf.org/html/rfc7540}}
\bibitem{webpack}{webpack concept\newline \url{https://webpack.js.org/concepts/}}
\end{thebibliography}

%\zakonczenie  % wklejenie recenzji i opinii

\end{document}
%+++ END +++
